{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11493160,"sourceType":"datasetVersion","datasetId":7204694}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install chromadb==0.4.24 sentence-transformers transformers joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:31:57.806341Z","iopub.execute_input":"2025-04-21T03:31:57.806629Z","iopub.status.idle":"2025-04-21T03:33:59.277280Z","shell.execute_reply.started":"2025-04-21T03:31:57.806603Z","shell.execute_reply":"2025-04-21T03:33:59.276413Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting chromadb==0.4.24\n  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\nCollecting build>=1.0.3 (from chromadb==0.4.24)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (2.32.3)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (2.11.3)\nCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.24)\n  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi>=0.95.2 (from chromadb==0.4.24)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.26.4)\nCollecting posthog>=2.4.0 (from chromadb==0.4.24)\n  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (4.13.1)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.24)\n  Downloading pulsar_client-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.24)\n  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.16.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.16.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (0.21.0)\nCollecting pypika>=0.48.9 (from chromadb==0.4.24)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.70.0)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.24)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (0.15.1)\nCollecting kubernetes>=28.1.0 (from chromadb==0.4.24)\n  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (9.0.0)\nRequirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb==0.4.24)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (3.10.15)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb==0.4.24)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb==0.4.24)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2025.1.31)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.27.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.3.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.4.24)\n  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.24)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.24) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.24) (75.1.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24) (1.67.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24)\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb==0.4.24)\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (1.17.2)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.24) (8.6.1)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.24)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.24)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.4.24) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28->chromadb==0.4.24) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28->chromadb==0.4.24) (3.10)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.24) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (14.0.0)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.14.0)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (14.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (4.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.24) (3.21.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (2.19.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.24) (3.7.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.24)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb==0.4.24) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb==0.4.24) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.24) (1.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (0.1.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.6.1)\nDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\nDownloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\nDownloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\nDownloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m65.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=e8e9e4eccb748dd8281a4216950824a7b70e112f2da8e19657b7ed3175817682\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, pulsar-client, protobuf, opentelemetry-util-http, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, nvidia-cusolver-cu12, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, onnxruntime, chroma-hnswlib, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.16.0\n    Uninstalling opentelemetry-api-1.16.0:\n      Successfully uninstalled opentelemetry-api-1.16.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.16.0\n    Uninstalling opentelemetry-sdk-1.16.0:\n      Successfully uninstalled opentelemetry-sdk-1.16.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.12 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-3.25.0 protobuf-5.29.4 pulsar-client-3.6.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.46.2 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport os\nfrom typing import List, Dict, Optional\nimport uuid\nimport warnings\nimport logging\nimport joblib\nimport chromadb\nfrom sentence_transformers import SentenceTransformer\nfrom chromadb.utils import embedding_functions\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport shutil\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nwarnings.filterwarnings('ignore', category=RuntimeWarning, module='pandas.io.formats.format')\n\ndef clean_text(text: str, preserve_case: bool = False) -> str:\n    if pd.isna(text) or text is None:\n        return \"\"\n    text = str(text)\n    text = re.sub(r'http\\S+|www\\S+|[\\w\\.-]+@[\\w\\.-]+', '', text)\n    text = re.sub(r'[^\\w\\s.,-]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text if preserve_case else text.lower()\n\ndef extract_features(description: str, category: str) -> Dict[str, bool]:\n    description = clean_text(description, preserve_case=False)\n    category = clean_text(category, preserve_case=False)\n    features = {'vegetarian': False, 'vegan': False, 'gluten_free': False, 'spicy': False}\n    vegetarian_keywords = ['vegetarian', 'vegan', 'plant-based', 'tofu', 'mushroom', 'eggplant', 'jackfruit', 'vegetable', 'amaranth', 'curry']\n    vegan_keywords = ['vegan', 'plant-based', 'no dairy', 'coconut milk']\n    non_veg_keywords = ['chicken', 'prawn', 'fish', 'mutton', 'pork', 'bacon', 'ham', 'choriz', 'beef', 'lamb']\n    if not any(keyword in description for keyword in non_veg_keywords):\n        if any(keyword in description for keyword in vegetarian_keywords):\n            features['vegetarian'] = True\n        if any(keyword in description for keyword in vegan_keywords) or (\n            features['vegetarian'] and 'cheese' not in description and 'egg' not in description\n        ):\n            features['vegan'] = True\n    gluten_free_keywords = ['gluten-free', 'rice', 'bhakri', 'no wheat']\n    if any(keyword in description for keyword in gluten_free_keywords):\n        features['gluten_free'] = True\n    spicy_keywords = ['spicy', 'chilli', 'masala', 'pepper', 'picante']\n    if 'coffee' not in category:\n        spicy_keywords.append('hot')\n    if any(keyword in description for keyword in spicy_keywords):\n        features['spicy'] = True\n    return features\n\ndef preprocess_menu_data(df: pd.DataFrame, column_mapping: Dict[str, str], restaurant_name: str = \"Unknown\", location: str = \"Unknown\") -> List[Dict]:\n    if df is None or df.empty:\n        logging.error(\"DataFrame is empty or None\")\n        return []\n    logging.info(f\"Raw DataFrame rows: {len(df)}\")\n    logging.info(\"First 5 rows of raw DataFrame:\\n\" + df.head().to_string())\n    df_processed = df.copy()\n    expected_columns = ['section', 'category', 'item_name', 'description', 'price']\n    missing_columns = [col for col in expected_columns if col not in column_mapping]\n    if missing_columns:\n        logging.warning(f\"Missing column mappings for {missing_columns}. Using empty strings.\")\n        for col in missing_columns:\n            df_processed[col] = ''\n    else:\n        for expected_col, actual_col in column_mapping.items():\n            if actual_col in df_processed.columns:\n                df_processed[expected_col] = df_processed[actual_col]\n            else:\n                logging.warning(f\"Column '{actual_col}' not found in DataFrame. Using empty strings.\")\n                df_processed[expected_col] = ''\n    df_normalized = df_processed.copy()\n    for col in ['section', 'category', 'item_name', 'description', 'price']:\n        if col in df_normalized.columns:\n            df_normalized[col] = df_normalized[col].apply(lambda x: clean_text(x, preserve_case=False))\n    duplicates = df_normalized[df_normalized.duplicated(subset=['section', 'category', 'item_name', 'description', 'price'], keep=False)]\n    if not duplicates.empty:\n        logging.warning(f\"Found {len(duplicates)} normalized duplicate rows:\\n\" + duplicates.head().to_string())\n    df_processed = df_processed.drop_duplicates(\n        subset=['section', 'category', 'item_name', 'description', 'price'],\n        keep='first',\n        ignore_index=True\n    )\n    logging.info(f\"After removing duplicates: {len(df_processed)}\")\n    for col in ['section', 'category', 'item_name', 'description']:\n        if col in df_processed.columns:\n            df_processed[col] = df_processed[col].apply(\n                lambda x: clean_text(x, preserve_case=(col in ['item_name', 'section']))\n            )\n    if 'price' in df_processed.columns:\n        df_processed['price'] = df_processed['price'].fillna('Price not available').str.strip()\n    else:\n        df_processed['price'] = 'Price not available'\n    df_processed['Features'] = df_processed.apply(\n        lambda row: extract_features(row['description'], row['category']), axis=1\n    )\n    df_processed['combined_text'] = (\n        df_processed['item_name'] + ' ' +\n        df_processed['description'] + ' ' +\n        df_processed['category'] + ' ' +\n        df_processed['section'] + ' ' +\n        ' '.join(df_processed['Features'].apply(lambda x: ' '.join([k for k, v in x.items() if v])))\n    ).apply(clean_text)\n    processed_data = []\n    for _, row in df_processed.iterrows():\n        menu_item = {\n            'id': str(uuid.uuid4()),\n            'restaurant_name': restaurant_name,\n            'location': location,\n            'section': row['section'],\n            'category': row['category'],\n            'item_name': row['item_name'],\n            'description': row['description'],\n            'price': row['price'],\n            'features': row['Features'],\n            'combined_text': row['combined_text']\n        }\n        processed_data.append(menu_item)\n    return processed_data\n\ndef preprocess_all_csvs(directory: str = \"/kaggle/input/restaurant\", default_column_mapping: Optional[Dict[str, str]] = None, restaurant_name: str = \"Unknown\", location: str = \"Unknown\") -> List[Dict]:\n    if default_column_mapping is None:\n        default_column_mapping = {\n            'section': 'Section',\n            'category': 'Category',\n            'item_name': 'Item Name',\n            'description': 'Description',\n            'price': 'Price'\n        }\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    if not csv_files:\n        logging.error(f\"No CSV files found in {directory}\")\n        return []\n    logging.info(f\"Found {len(csv_files)} CSV files: {csv_files}\")\n    all_processed_data = []\n    for csv_file in csv_files:\n        file_path = os.path.join(directory, csv_file)\n        logging.info(f\"Processing {file_path}\")\n        try:\n            df = pd.read_csv(\n                file_path,\n                encoding='utf-8',\n                engine='python',\n                keep_default_na=True,\n                na_values=['', 'NaN']\n            )\n            processed_data = preprocess_menu_data(\n                df=df,\n                column_mapping=default_column_mapping,\n                restaurant_name=f\"{restaurant_name}_{csv_file.replace('.csv', '')}\",\n                location=location\n            )\n            if processed_data:\n                all_processed_data.extend(processed_data)\n                logging.info(f\"Successfully processed {len(processed_data)} items from {csv_file}\")\n            else:\n                logging.warning(f\"No data processed from {csv_file}\")\n        except Exception as e:\n            logging.error(f\"Error processing {csv_file}: {str(e)}\")\n            continue\n    logging.info(f\"Total processed items from all CSVs: {len(all_processed_data)}\")\n    if all_processed_data:\n        combined_df = pd.DataFrame(all_processed_data)\n        combined_df.to_csv('combined_processed_data.csv', index=False)\n        os.makedirs('/kaggle/working/cache', exist_ok=True)\n        cache_file = '/kaggle/working/cache/preprocessed_data.pkl'\n        joblib.dump(all_processed_data, cache_file)\n        logging.info(f\"Saved preprocessed data to {cache_file}\")\n    return all_processed_data\n\n# Clean up existing Chroma data to avoid conflicts\nshutil.rmtree(\"/kaggle/working/chroma/\", ignore_errors=True)\nlogging.info(\"Cleaned up existing Chroma data directory\")\n\n# Initialize Chroma client\nclient = chromadb.PersistentClient(path=\"/kaggle/working/chroma/\")\nlogging.info(\"Initialized Chroma client with persistent storage\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:33:59.278334Z","iopub.execute_input":"2025-04-21T03:33:59.278598Z","iopub.status.idle":"2025-04-21T03:34:26.928441Z","shell.execute_reply.started":"2025-04-21T03:33:59.278576Z","shell.execute_reply":"2025-04-21T03:34:26.927878Z"}},"outputs":[{"name":"stderr","text":"2025-04-21 03:34:13.586660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745206453.800081      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745206453.859706      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class MenuIndexer:\n    \"\"\"Efficient indexing system using ChromaDB with a shared client.\"\"\"\n    def __init__(self, processed_data: list):\n        self.data = processed_data\n        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n        self.client = client  # Use the global client\n        self.collection = None\n        self.build_index()\n\n    def build_index(self):\n        \"\"\"Build ChromaDB collection with embeddings and metadata.\"\"\"\n        if not self.data:\n            raise ValueError(\"No data to index\")\n        \n        # Clean up existing collection if it exists\n        try:\n            self.client.delete_collection(name=\"menu_knowledge_base\")\n            logging.info(\"Deleted existing collection to avoid conflicts\")\n        except Exception:\n            pass  # Ignore if collection doesn't exist\n        \n        sentence_embed = embedding_functions.SentenceTransformerEmbeddingFunction(\n            model_name='all-MiniLM-L6-v2'\n        )\n        \n        self.collection = self.client.get_or_create_collection(\n            name=\"menu_knowledge_base\",\n            embedding_function=sentence_embed\n        )\n        \n        ids = [item['id'] for item in self.data]\n        texts = [item['combined_text'] for item in self.data]\n        metadata = [{\n            'restaurant_name': item['restaurant_name'],\n            'location': item['location'],\n            'section': item['section'],\n            'category': item['category'],\n            'item_name': item['item_name'],\n            'description': item['description'],\n            'price': item['price'],\n            'vegetarian': str(item['features']['vegetarian']).lower(),\n            'vegan': str(item['features']['vegan']).lower(),\n            'gluten_free': str(item['features']['gluten_free']).lower(),\n            'spicy': str(item['features']['spicy']).lower()\n        } for item in self.data]\n        \n        self.collection.add(\n            ids=ids,\n            documents=texts,\n            metadatas=metadata\n        )\n        logging.info(f\"ChromaDB collection built with {len(self.data)} items\")\n\n    def search(self, query: str, top_k: int = 5, filters: Optional[Dict] = None) -> list:\n        \"\"\"Search the ChromaDB collection for relevant items.\"\"\"\n        where_clause = {}\n        if filters:\n            conditions = []\n            for key, value in filters.items():\n                if key in ['vegetarian', 'vegan', 'gluten_free', 'spicy']:\n                    conditions.append({key: str(value).lower()})\n                elif key == 'category':\n                    conditions.append({'category': value})\n                elif key == 'item_name':\n                    conditions.append({'item_name': value})\n            if conditions:\n                where_clause = {\"$and\": conditions} if len(conditions) > 1 else conditions[0]\n\n        results = self.collection.query(\n            query_texts=[query],\n            n_results=top_k,\n            where=where_clause if where_clause else None\n        )\n        \n        retrieved_ids = results['ids'][0]\n        retrieved_items = [item for item in self.data if item['id'] in retrieved_ids]\n        distances = results['distances'][0]\n        for item, dist in zip(retrieved_items, distances):\n            item['distance'] = float(dist)\n        \n        return retrieved_items\n\nclass MenuRAGChatbot:\n    \"\"\"RAG-based chatbot with retrieval and generation components using ChromaDB.\"\"\"\n    def __init__(self, indexer):\n        self.indexer = indexer\n        self.tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n        self.model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n        self.history = []\n        self.max_history = 5\n\n    def add_to_history(self, query: str, response: str):\n        self.history.append({'query': query, 'response': response})\n        if len(self.history) > self.max_history:\n            self.history.pop(0)\n\n    def retrieve(self, query: str, filters: Optional[Dict] = None) -> list:\n        \"\"\"Retrieve relevant menu items based on query and filters.\"\"\"\n        query_filters = {}\n        \n        # Extract feature-based filters\n        for feature in ['vegetarian', 'vegan', 'gluten_free', 'spicy']:\n            if feature in query.lower():\n                query_filters[feature] = True\n        \n        # Extract category or item-specific filters\n        if 'espresso' in query.lower():\n            query_filters['item_name'] = 'espresso'\n        if 'spicy' in query.lower():\n            query_filters['spicy'] = True\n        \n        # Handle price range queries\n        price_range = re.search(r'\\$(\\d+)-?\\$?(\\d+)?', query)\n        if price_range:\n            min_price, max_price = price_range.groups()\n            min_price = float(min_price)\n            max_price = float(max_price) if max_price else min_price + 10\n            # Filter items in post-processing since Chroma doesn't support numeric range queries directly\n            items = self.indexer.search(query, top_k=10, filters=query_filters or filters)\n            return [\n                item for item in items\n                if item['price'] != 'Price not available' and\n                min_price <= float(re.sub(r'[^\\d.]', '', item['price'])) <= max_price\n            ]\n        \n        return self.indexer.search(query, top_k=5, filters=query_filters or filters)\n\n    def generate_response(self, query: str, retrieved_items: list) -> str:\n        \"\"\"Generate a response based on retrieved items.\"\"\"\n        if not retrieved_items:\n            return \"Sorry, I couldn't find any relevant menu items for your query. Try asking about specific dishes or dietary preferences!\"\n        \n        context = \"\\n\".join([\n            f\"{item['item_name']} ({item['restaurant_name']}): {item['description']} \"\n            f\"(Price: {item['price']}, Features: {', '.join([k for k, v in item['features'].items() if v])})\"\n            for item in retrieved_items\n        ])\n        \n        history_context = \"\\n\".join([f\"Previous query: {h['query']}, Response: {h['response']}\" for h in self.history[-2:]])\n        if history_context:\n            context = f\"{context}\\nPrevious context:\\n{history_context}\"\n        \n        prompt = f\"Answer the query based on the following menu items:\\n{context}\\n\\nQuery: {query}\\nAnswer:\"\n        inputs = self.tokenizer(prompt, return_tensors='pt', max_length=512, truncation=True)\n        outputs = self.model.generate(\n            inputs['input_ids'],\n            max_length=200,\n            num_beams=5,\n            early_stopping=True\n        )\n        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return response\n\n    def handle_query(self, query: str) -> str:\n        query = clean_text(query)\n        if any(keyword in query.lower() for keyword in ['weather', 'news', 'stock']):\n            return \"Sorry, I can only assist with menu-related queries.\"\n        if not any(word in query.lower() for word in ['what', 'which', 'price', 'diet', 'feature', 'compare']):\n            return \"Could you please clarify? For example, ask about menu items, prices, or dietary options.\"\n        retrieved_items = self.retrieve(query)\n        response = self.generate_response(query, retrieved_items)\n        self.add_to_history(query, response)\n        return response\n\n    def get_history(self) -> list:\n        return self.history.copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:34:26.929563Z","iopub.execute_input":"2025-04-21T03:34:26.930202Z","iopub.status.idle":"2025-04-21T03:34:26.949783Z","shell.execute_reply.started":"2025-04-21T03:34:26.930182Z","shell.execute_reply":"2025-04-21T03:34:26.949288Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def main():\n    # Load cached preprocessed data or process if not available\n    cache_file = '/kaggle/working/cache/preprocessed_data.pkl'\n    try:\n        processed_data = joblib.load(cache_file)\n        logging.info(f\"Loaded preprocessed data from {cache_file}\")\n    except (FileNotFoundError, Exception) as e:\n        logging.warning(f\"Cache load failed: {e}. Processing CSVs...\")\n        processed_data = preprocess_all_csvs(\n            directory=\"/kaggle/input/restaurant\",\n            default_column_mapping=None,\n            restaurant_name=\"O Pedra\",\n            location=\"Unknown\"\n        )\n        if not processed_data:\n            logging.error(\"No data processed. Exiting.\")\n            return\n    \n    # Initialize indexer\n    indexer = MenuIndexer(processed_data)\n    \n    # Initialize chatbot\n    chatbot = MenuRAGChatbot(indexer)\n\n    \n    # Interactive mode\n    while True:\n        user_input = input(\"Enter your query (or 'exit' to quit): \").strip()\n        if user_input.lower() == 'exit':\n            break\n        response = chatbot.handle_query(user_input)\n        print(f\"Response: {response}\")\n        print(f\"History: {chatbot.get_history()}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:35:02.933754Z","iopub.execute_input":"2025-04-21T03:35:02.934359Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e404483cd4544c285a3964ec0e9ae20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3101ce9a45d84121b6aa8e69cd0b48d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19640ddd17b041baadfd5011a10c155c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9abb05796e044ec2bb0a93eadc6c35de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5b071338ec4bceabdb6f4f8ccccf95"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"326aa67595294702aaceedcf652d9ce3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9925c0996b424cc7af3b4b7e670476ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8fbc3e6ce743498560f273a4863a4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3aedebdd8b4460a8ba070c8a54c6958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b71470b8874428996972ea14d5b2cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a977852347446ea1f0a02078485b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a7417f83fa40ec8720348713a8bec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e210fd72874719b28b034f1985ca67"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8fb5b2f7a249078e1916fe3acdb860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e78df1f5b544fce90f60ce94d586309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457f065dbb2143069927801b76e1c9fb"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b859edd1b5b433eb9441e0f0e080e4e"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5204fc39caac457cbfd10d463c3f0c89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aebb149deba44e6294688f378301fa1a"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Enter your query (or 'exit' to quit):  Suggest some good restaurants\n"},{"name":"stdout","text":"Response: Could you please clarify? For example, ask about menu items, prices, or dietary options.\nHistory: []\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your query (or 'exit' to quit):  Do you know O Pedra?\n"},{"name":"stdout","text":"Response: Could you please clarify? For example, ask about menu items, prices, or dietary options.\nHistory: []\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your query (or 'exit' to quit):  Where is O pedro?\n"},{"name":"stdout","text":"Response: Could you please clarify? For example, ask about menu items, prices, or dietary options.\nHistory: []\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your query (or 'exit' to quit):  Veronica's Coffee\n"},{"name":"stdout","text":"Response: Could you please clarify? For example, ask about menu items, prices, or dietary options.\nHistory: []\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}